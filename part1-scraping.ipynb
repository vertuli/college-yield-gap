{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.collegedata.com/cs/data/college/college_pg06_tmpl.jhtml?schoolId=5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import clear_output\n",
    "from requests import get\n",
    "from os.path import isfile\n",
    "\n",
    "START_ID = 1\n",
    "END_ID = 5000\n",
    "CHUNKSIZE = 10\n",
    "\n",
    "path = 'data/scraped_collegedata.csv'\n",
    "if isfile(path):\n",
    "    START_ID = pd.read_csv(path)['page_id'].max() + 1\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for page_id in range(START_ID, END_ID + 1):\n",
    "    scraped_school = {}\n",
    "    for i in range(0,len(BASE_URLS)):\n",
    "        url = BASE_URLS[i] + str(page_id)\n",
    "        \n",
    "        print(url)   # Print a status update.\n",
    "        \n",
    "        response = get(url)\n",
    "        page = BeautifulSoup(response.text, \"lxml\")\n",
    "        if page.h1:\n",
    "            scraped_school['name'] = page.h1.string\n",
    "            scraped_school.update(scrape(page, page_labels[i]))\n",
    "            series = pd.Series(scraped_school, name=page_id)\n",
    "            df = df.append(series)\n",
    "        \n",
    "        clear_output(wait = True)   # Clear the status update.\n",
    "    \n",
    "    if (page_id - START_ID) % CHUNKSIZE == 0:\n",
    "        if not isfile(path):\n",
    "            df.to_csv(path, mode='w', header=True, index_label='page_id')\n",
    "        else: # else it exists so append without writing the header\n",
    "            df.to_csv(path, mode='a', header=False)\n",
    "        \n",
    "        # Clear the dataframe.\n",
    "        df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 of school 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-bfdc321d3cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# Scrape the current batch and convert the results to a pandas dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mscraped_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_start_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mbatch_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraped_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-bfdc321d3cd6>\u001b[0m in \u001b[0;36mscrape_batch\u001b[0;34m(batch_start_school_id)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Scraping page {} of school {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschool_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_req_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelvertuli/anaconda/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelvertuli/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import isfile\n",
    "from requests import get\n",
    "from requests_futures.sessions import FuturesSession\n",
    "from IPython.core.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Scraper start and stop information.\n",
    "BASE_URL_1 = \"http://www.collegedata.com/cs/data/college/college_pg0\"\n",
    "BASE_URL_2 = \"_tmpl.jhtml?schoolId=\"\n",
    "SCHOOL_ID_START = 1\n",
    "SCHOOL_ID_END = 5000\n",
    "BATCH_SIZE = 10\n",
    "EMPTY_TITLE = \"Retrieve a Saved Search\"\n",
    "RAW_CSV_PATH = \"data/scraped_collegedata.csv\"\n",
    "PAGE_IDS = np.arange(1, 7)\n",
    "\n",
    "\n",
    "def scrape_page(soup):\n",
    "    \n",
    "    scraped_page = {}\n",
    "    scraped_page['Name'] = soup.h1.string\n",
    "    \n",
    "    th_tags = soup.find(id='tabcontwrap').find_all('th')\n",
    "    for th_tag in th_tags:\n",
    "        if th_tag.parent:\n",
    "            if th_tag.parent.td:\n",
    "                key = \" \".join(th_tag.stripped_strings)\n",
    "                while key in scraped_page.keys():\n",
    "                    key += '*'\n",
    "                value = \" \".join(th_tag.parent.td.stripped_strings)\n",
    "                scraped_page[key] = value\n",
    "                \n",
    "    return scraped_page\n",
    "\n",
    "\n",
    "def get_batch_reqs(batch_school_ids):\n",
    "    batch_urls = {school_id: \\\n",
    "                  {page_id: BASE_URL_1 + str(page_id) \\\n",
    "                   + BASE_URL_2 + str(school_id) \\\n",
    "                    for page_id in PAGE_IDS} \\\n",
    "                     for school_id in batch_school_ids}\n",
    "    \n",
    "    session = FuturesSession()\n",
    "    \n",
    "    batch_reqs = {school_id: \\\n",
    "                  {page_id: session.get(batch_urls[school_id][page_id]) \\\n",
    "                   for page_id in PAGE_IDS} \\\n",
    "                    for school_id in batch_school_ids}\n",
    "    \n",
    "    return batch_reqs\n",
    "\n",
    "    \n",
    "    \n",
    "def check_scrape_errors(soup):\n",
    "    if not soup.h1:\n",
    "        return True\n",
    "    elif soup.h1.string == EMPTY_TITLE:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_batch(batch_start_school_id):\n",
    "    batch_school_ids = np.arange(batch_start_school_id, \n",
    "                                 batch_start_school_id + BATCH_SIZE)\n",
    "    batch_reqs = get_batch_reqs(batch_school_ids)\n",
    "    \n",
    "    scraped_batch = {}\n",
    "    for school_id in batch_school_ids:\n",
    "        page_reqs = batch_reqs[school_id]\n",
    "        \n",
    "        scraped_school = {}\n",
    "        scraped_school['School Id'] = school_id\n",
    "        \n",
    "        for page_id, page_req in page_reqs.items():\n",
    "            \n",
    "            # Print a status message.\n",
    "            print(\"Scraping page {} of school {}\".format(page_id, school_id))\n",
    "            \n",
    "            result = page_req.result()\n",
    "            \n",
    "            if check_req_errors(result):\n",
    "                break\n",
    "                \n",
    "            soup = BeautifulSoup(result.text, \"lxml\")\n",
    "            \n",
    "            if check_scrape_errors(soup):\n",
    "                break\n",
    "            \n",
    "            scraped_page = scrape_page(soup)\n",
    "            \n",
    "            scraped_school.update(scraped_page)\n",
    "            \n",
    "            # Clear the status update.\n",
    "            clear_output(wait = True)\n",
    "        \n",
    "        scraped_batch[school_id] = scraped_school\n",
    "    \n",
    "    return scraped_batch\n",
    "\n",
    "\n",
    "\n",
    "# If already partially scraped, start where previoulsy left off.\n",
    "if isfile(path):\n",
    "    SCHOOL_ID_START = pd.read_csv(path)['School Id'].max() + 1\n",
    "\n",
    "# Create numpy arrays of all requested page and school ids.\n",
    "school_ids = np.arange(SCHOOL_ID_START, SCHOOL_ID_END + 1)\n",
    "\n",
    "# Scrape the range of school ids in batches.\n",
    "for batch_start_id in range(SCHOOL_ID_START, SCHOOL_ID_END + 1, BATCH_SIZE):\n",
    "    \n",
    "    # Scrape the current batch and convert the results to a pandas dataframe.\n",
    "    scraped_batch = scrape_batch(batch_start_id)\n",
    "    \n",
    "    batch_df = pd.DataFrame.from_dict(scraped_batch, orient='index')\n",
    "    \n",
    "    # Append the dataframe to .csv:\n",
    "    if not isfile(RAW_CSV_PATH):\n",
    "        # If .csv file doesn't already exist, create it and include headers...\n",
    "        batch_df.to_csv(RAW_CSV_PATH, mode='w', header=True, \n",
    "                        index_label='School Id')\n",
    "    else:\n",
    "        # ...or else just append the scraped data to the .csv without headers.\n",
    "        batch_df.to_csv(RAW_CSV_PATH, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Penn State University Park'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests import get\n",
    "URL = \"https://www.collegedata.com/cs/data/college/college_pg02_tmpl.jhtml?schoolId=59\"\n",
    "response = get(URL)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import isfile\n",
    "from requests import get\n",
    "from requests_futures.sessions import FuturesSession\n",
    "from IPython.core.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "\n",
    "def get_clean_string(tag):\n",
    "    child_tags = tag.find_all(True)\n",
    "    if child_tags:\n",
    "        for child_tag in tag.find_all(True):\n",
    "            if child_tag.name == 'div':\n",
    "                child_tag.unwrap()\n",
    "            else:\n",
    "                child_tag.decompose()     \n",
    "    value = \" \".join(tag.stripped_strings)\n",
    "    \n",
    "    return value\n",
    "\n",
    "\n",
    "def scrape_row(tr_tag):\n",
    "    scraped_row = {}\n",
    "    \n",
    "    th_tags = tr_tag.find_all('th')\n",
    "    if not th_tags:\n",
    "        return None\n",
    "    \n",
    "    th_tag = th_tags[0]\n",
    "    label = get_clean_string(th_tag)\n",
    "    if not label:\n",
    "        return None\n",
    "    \n",
    "    values = []\n",
    "    parent = th_tag.parent\n",
    "    if not parent:\n",
    "        return None\n",
    "    \n",
    "    td_tags = parent.find_all('td')\n",
    "    if not td_tags:\n",
    "        return None\n",
    "    \n",
    "    for td_tag in td_tags:\n",
    "        value = get_clean_string(td_tag)\n",
    "        values.append(value)\n",
    "    \n",
    "    scraped_row[label] = values\n",
    "    return scraped_row\n",
    "\n",
    "    \n",
    "def scrape_table(thead_tag):\n",
    "    # Get the column labels from <thead>, if they exist.\n",
    "    # If they do not, use a number label placeholder instead.\n",
    "    column_labels = []\n",
    "    thead_td_tags = thead_tag.find_all('td')\n",
    "    if not thead_td_tags:\n",
    "        return None\n",
    "    for thead_td_tag in thead_td_tags:\n",
    "        i = 0\n",
    "        if thead_td_tag.string:\n",
    "            column_label = thead_td_tag.string\n",
    "        else:\n",
    "            column_label = None\n",
    "        while column_label in column_labels:\n",
    "            if column_label:\n",
    "                column_label += '*'\n",
    "            else:\n",
    "                column_label = '*'\n",
    "        column_labels.append(column_label)\n",
    "\n",
    "    # Get the <th> strings in the <tbody>.\n",
    "    if thead_tag.parent:\n",
    "        if not thead_tag.parent.tbody:\n",
    "            return None\n",
    "        tbody_tr_tags = thead_tag.parent.tbody.find_all('tr')\n",
    "        if not tbody_tr_tags:\n",
    "            return None\n",
    "    \n",
    "    scraped_table = {}\n",
    "    # Scrape the rows of each table.\n",
    "    for tr_tag in tbody_tr_tags:\n",
    "        scraped_row = {}\n",
    "        raw_scraped_row = scrape_row(tr_tag)\n",
    "        if raw_scraped_row:\n",
    "            all_raw_values = []\n",
    "            for raw_value in raw_scraped_row.values():\n",
    "                all_raw_values += raw_value\n",
    "            unique_vals = set(all_raw_values)\n",
    "                \n",
    "            for raw_label, raw_values in raw_scraped_row.items():\n",
    "                for i, raw_value in enumerate(raw_values):\n",
    "                    if (len(unique_vals) == 2) and ('X' in unique_vals):\n",
    "                        if raw_value == 'X':\n",
    "                            scraped_row[raw_label] = column_labels[i]\n",
    "                    else:\n",
    "                        column_label = column_labels[i]\n",
    "                        label = raw_label\n",
    "                        if column_label:\n",
    "                            label = raw_label + \" - \" + column_label\n",
    "                        scraped_row[label] = raw_value\n",
    "                        \n",
    "        scraped_table.update(scraped_row)\n",
    "        \n",
    "    return scraped_table\n",
    "\n",
    "\n",
    "def remove_sports_offered_table(soup):\n",
    "    comment_tag = soup.find(string=\" Sports start \")\n",
    "    if not comment_tag:\n",
    "        return None\n",
    "    table_tag = comment_tag.find_next_sibling('table')\n",
    "    if not table_tag:\n",
    "        return None\n",
    "    table_tag.decompose()\n",
    "    return None\n",
    "\n",
    "\n",
    "def fix_population_label(soup):\n",
    "    regexp = re.compile('Population')\n",
    "    th_tags = soup.find_all(string=regexp)\n",
    "    if not th_tags:\n",
    "        return None\n",
    "    for th_tag in th_tags:\n",
    "        th_tag.string.replace_with('City Population')\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_section(soup, section_id):\n",
    "    tag = soup.find(id = section_id)\n",
    "    if not tag:\n",
    "        return None\n",
    "    tag.decompose()\n",
    "    return None\n",
    "\n",
    "\n",
    "def preprocess_soup(soup):\n",
    "    remove_sports_offered_table(soup)\n",
    "    fix_population_label(soup)\n",
    "    remove_section(soup, \"section10\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_dict(dict_1, dict_2):\n",
    "    if dict_2:\n",
    "        temp_dict = {}\n",
    "        for key, value in dict_2.items():\n",
    "            if key not in dict_1.keys():\n",
    "                temp_dict[key] = value\n",
    "            elif value != dict_1[key]:\n",
    "                while key in dict_1.keys():\n",
    "                    key += '*'\n",
    "                temp_dict[key] = value\n",
    "        dict_1.update(temp_dict)\n",
    "    return None\n",
    "        \n",
    "\n",
    "def scrape_page(soup):    \n",
    "    \n",
    "    scraped_page = {}\n",
    "\n",
    "    # Scrape data from tables with <thead> and <tbody> tags, if any.\n",
    "    thead_tags = soup.find(id='tabcontwrap').find_all('thead')\n",
    "    if thead_tags:\n",
    "        for thead_tag in thead_tags:\n",
    "            scraped_table = scrape_table(thead_tag)\n",
    "            add_dict(scraped_page, scraped_table)\n",
    "        \n",
    "            # Delete entire table from soup.\n",
    "            thead_tag.parent.decompose()\n",
    "        \n",
    "\n",
    "    # Scrape remaining table rows.\n",
    "    tr_tags = soup.find(id='tabcontwrap').find_all('tr')\n",
    "    if tr_tags:\n",
    "        for tr_tag in tr_tags:\n",
    "            scraped_row = scrape_row(tr_tag)\n",
    "            if scraped_row:\n",
    "                for label, values in scraped_row.items():\n",
    "                    scraped_row[label] = values[0]\n",
    "            \n",
    "                add_dict(scraped_page, scraped_row)\n",
    "    \n",
    "    return scraped_page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.collegedata.com/cs/data/college/college_pg06_tmpl.jhtml?schoolId=21\n",
      "Status Code: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Academic GPA</th>\n",
       "      <th>Standardized Tests</th>\n",
       "      <th>Essay</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Web Site</th>\n",
       "      <th>Institution Type</th>\n",
       "      <th>Coeducational</th>\n",
       "      <th>Undergraduate Students</th>\n",
       "      <th>Women</th>\n",
       "      <th>...</th>\n",
       "      <th>Top Areas (By Money Awarded)</th>\n",
       "      <th>Creative Arts/Performance Award Areas</th>\n",
       "      <th>Special Achievements/Activities Award Areas</th>\n",
       "      <th>Special Characteristics Award Areas</th>\n",
       "      <th>Work-Study Programs</th>\n",
       "      <th>Average Earnings from On-Campus Employment</th>\n",
       "      <th>Number of Awards*</th>\n",
       "      <th>Number of Awards**</th>\n",
       "      <th>Number of Awards***</th>\n",
       "      <th>Coeducational*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bryn Athyn College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>326</td>\n",
       "      <td>165 (50.6%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5,266</td>\n",
       "      <td>3,603 (68.4%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Albany College of Pharmacy and Health Sciences</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,078</td>\n",
       "      <td>646 (59.9%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Children and Siblings of Alumni, Children of F...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Albertus Magnus College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,220</td>\n",
       "      <td>814 (66.7%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Albright College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2,015</td>\n",
       "      <td>1,195 (59.3%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alfred University</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,707</td>\n",
       "      <td>818 (47.9%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Allegheny College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,802</td>\n",
       "      <td>982 (54.5%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Art/Fine Arts, Dance, Music, Performing Arts, ...</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Adult Students, Children of Educators, Childre...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$2,475</td>\n",
       "      <td>8</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>301</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DeSales University</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2,345</td>\n",
       "      <td>1,433 (61.1%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alvernia University</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2,323</td>\n",
       "      <td>1,716 (73.9%)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>American International College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,372</td>\n",
       "      <td>812 (59.2%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Children and Siblings of Alumni, Children of F...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$640</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sacred Heart University</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5,603</td>\n",
       "      <td>3,581 (63.9%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Applied Art and Design, Art/Fine Arts, Cinema/...</td>\n",
       "      <td>Community Service, Hobbies/Interests, Leadersh...</td>\n",
       "      <td>Adult Students, Children and Siblings of Alumn...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$1,679</td>\n",
       "      <td>991</td>\n",
       "      <td>2,298</td>\n",
       "      <td>552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>St. Joseph's College - Long Island Campus</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3,059</td>\n",
       "      <td>2,022 (66.1%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Community Service, Leadership</td>\n",
       "      <td>Children and Siblings of Alumni, Children of F...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$2,568</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Amherst College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Very Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,836</td>\n",
       "      <td>908 (49.5%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$1,901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Saint Anselm College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,964</td>\n",
       "      <td>1,196 (60.9%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Children and Siblings of Alumni, Children of E...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$1,482</td>\n",
       "      <td>304</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>288</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>St. Bonaventure University</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td>Important</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,627</td>\n",
       "      <td>785 (48.2%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Journalism/Publications, Music, Performing Arts</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Children of Faculty/Staff, Local/State Student...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>$927</td>\n",
       "      <td>78</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anna Maria College</td>\n",
       "      <td>Very Important</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Considered</td>\n",
       "      <td>Considered</td>\n",
       "      <td></td>\n",
       "      <td>Private</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1,128</td>\n",
       "      <td>683 (60.5%)</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Music</td>\n",
       "      <td>Religious Involvement</td>\n",
       "      <td>Children of Faculty/Staff, Local/State Student...</td>\n",
       "      <td>Federal work study available, other work study...</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name    Academic GPA  \\\n",
       "1                                             None             NaN   \n",
       "2                                             None             NaN   \n",
       "3                                             None             NaN   \n",
       "4                                             None             NaN   \n",
       "5                                             None             NaN   \n",
       "6                               Bryn Athyn College  Very Important   \n",
       "7                               Adelphi University       Important   \n",
       "8   Albany College of Pharmacy and Health Sciences  Very Important   \n",
       "9                          Albertus Magnus College  Very Important   \n",
       "10                                Albright College  Very Important   \n",
       "11                               Alfred University  Very Important   \n",
       "12                               Allegheny College  Very Important   \n",
       "13                              DeSales University  Very Important   \n",
       "14                             Alvernia University  Very Important   \n",
       "15                  American International College  Very Important   \n",
       "16                         Sacred Heart University  Very Important   \n",
       "17       St. Joseph's College - Long Island Campus  Very Important   \n",
       "18                                 Amherst College  Very Important   \n",
       "19                            Saint Anselm College  Very Important   \n",
       "20                      St. Bonaventure University  Very Important   \n",
       "21                              Anna Maria College  Very Important   \n",
       "\n",
       "   Standardized Tests           Essay Extracurricular Activities Web Site  \\\n",
       "1                 NaN             NaN                        NaN      NaN   \n",
       "2                 NaN             NaN                        NaN      NaN   \n",
       "3                 NaN             NaN                        NaN      NaN   \n",
       "4                 NaN             NaN                        NaN      NaN   \n",
       "5                 NaN             NaN                        NaN      NaN   \n",
       "6      Very Important  Very Important                 Considered            \n",
       "7           Important       Important                  Important            \n",
       "8      Very Important       Important                  Important            \n",
       "9          Considered       Important                 Considered            \n",
       "10         Considered      Considered                 Considered            \n",
       "11          Important       Important             Very Important            \n",
       "12         Considered      Considered                  Important            \n",
       "13          Important       Important                 Considered            \n",
       "14     Very Important       Important                  Important            \n",
       "15         Considered       Important                 Considered            \n",
       "16         Considered       Important                  Important            \n",
       "17          Important       Important                  Important            \n",
       "18     Very Important  Very Important             Very Important            \n",
       "19         Considered       Important                  Important            \n",
       "20          Important       Important                  Important            \n",
       "21         Considered      Considered                 Considered            \n",
       "\n",
       "   Institution Type Coeducational Undergraduate Students          Women  \\\n",
       "1               NaN           NaN                    NaN            NaN   \n",
       "2               NaN           NaN                    NaN            NaN   \n",
       "3               NaN           NaN                    NaN            NaN   \n",
       "4               NaN           NaN                    NaN            NaN   \n",
       "5               NaN           NaN                    NaN            NaN   \n",
       "6           Private           Yes                    326    165 (50.6%)   \n",
       "7           Private           Yes                  5,266  3,603 (68.4%)   \n",
       "8           Private           Yes                  1,078    646 (59.9%)   \n",
       "9           Private           Yes                  1,220    814 (66.7%)   \n",
       "10          Private           Yes                  2,015  1,195 (59.3%)   \n",
       "11          Private           Yes                  1,707    818 (47.9%)   \n",
       "12          Private           Yes                  1,802    982 (54.5%)   \n",
       "13          Private           Yes                  2,345  1,433 (61.1%)   \n",
       "14          Private           Yes                  2,323  1,716 (73.9%)   \n",
       "15          Private           Yes                  1,372    812 (59.2%)   \n",
       "16          Private           Yes                  5,603  3,581 (63.9%)   \n",
       "17          Private           Yes                  3,059  2,022 (66.1%)   \n",
       "18          Private           Yes                  1,836    908 (49.5%)   \n",
       "19          Private           Yes                  1,964  1,196 (60.9%)   \n",
       "20          Private           Yes                  1,627    785 (48.2%)   \n",
       "21          Private           Yes                  1,128    683 (60.5%)   \n",
       "\n",
       "        ...       Top Areas (By Money Awarded)  \\\n",
       "1       ...                                NaN   \n",
       "2       ...                                NaN   \n",
       "3       ...                                NaN   \n",
       "4       ...                                NaN   \n",
       "5       ...                                NaN   \n",
       "6       ...                                NaN   \n",
       "7       ...                                NaN   \n",
       "8       ...                                      \n",
       "9       ...                                NaN   \n",
       "10      ...                                NaN   \n",
       "11      ...                                NaN   \n",
       "12      ...                                      \n",
       "13      ...                                NaN   \n",
       "14      ...                                NaN   \n",
       "15      ...                                      \n",
       "16      ...                                      \n",
       "17      ...                                      \n",
       "18      ...                                      \n",
       "19      ...                                      \n",
       "20      ...                                      \n",
       "21      ...                                      \n",
       "\n",
       "                Creative Arts/Performance Award Areas  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                        Not reported   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12  Art/Fine Arts, Dance, Music, Performing Arts, ...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                       Not reported   \n",
       "16  Applied Art and Design, Art/Fine Arts, Cinema/...   \n",
       "17                                       Not reported   \n",
       "18                                       Not reported   \n",
       "19                                       Not reported   \n",
       "20    Journalism/Publications, Music, Performing Arts   \n",
       "21                                              Music   \n",
       "\n",
       "          Special Achievements/Activities Award Areas  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                        Not reported   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                       Not reported   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                       Not reported   \n",
       "16  Community Service, Hobbies/Interests, Leadersh...   \n",
       "17                      Community Service, Leadership   \n",
       "18                                       Not reported   \n",
       "19                                       Not reported   \n",
       "20                                       Not reported   \n",
       "21                              Religious Involvement   \n",
       "\n",
       "                  Special Characteristics Award Areas  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   Children and Siblings of Alumni, Children of F...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12  Adult Students, Children of Educators, Childre...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  Children and Siblings of Alumni, Children of F...   \n",
       "16  Adult Students, Children and Siblings of Alumn...   \n",
       "17  Children and Siblings of Alumni, Children of F...   \n",
       "18                                       Not reported   \n",
       "19  Children and Siblings of Alumni, Children of E...   \n",
       "20  Children of Faculty/Staff, Local/State Student...   \n",
       "21  Children of Faculty/Staff, Local/State Student...   \n",
       "\n",
       "                                  Work-Study Programs  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   Federal work study available, other work study...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12  Federal work study available, other work study...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  Federal work study available, other work study...   \n",
       "16  Federal work study available, other work study...   \n",
       "17  Federal work study available, other work study...   \n",
       "18  Federal work study available, other work study...   \n",
       "19  Federal work study available, other work study...   \n",
       "20  Federal work study available, other work study...   \n",
       "21  Federal work study available, other work study...   \n",
       "\n",
       "   Average Earnings from On-Campus Employment Number of Awards*  \\\n",
       "1                                         NaN               NaN   \n",
       "2                                         NaN               NaN   \n",
       "3                                         NaN               NaN   \n",
       "4                                         NaN               NaN   \n",
       "5                                         NaN               NaN   \n",
       "6                                         NaN               NaN   \n",
       "7                                         NaN               NaN   \n",
       "8                                Not reported               NaN   \n",
       "9                                         NaN               NaN   \n",
       "10                                        NaN               NaN   \n",
       "11                                        NaN               NaN   \n",
       "12                                     $2,475                 8   \n",
       "13                                        NaN               NaN   \n",
       "14                                        NaN               NaN   \n",
       "15                                       $640      Not reported   \n",
       "16                                     $1,679               991   \n",
       "17                                     $2,568      Not reported   \n",
       "18                                     $1,901               NaN   \n",
       "19                                     $1,482               304   \n",
       "20                                       $927                78   \n",
       "21                               Not reported               NaN   \n",
       "\n",
       "   Number of Awards** Number of Awards*** Coeducational*  \n",
       "1                 NaN                 NaN            NaN  \n",
       "2                 NaN                 NaN            NaN  \n",
       "3                 NaN                 NaN            NaN  \n",
       "4                 NaN                 NaN            NaN  \n",
       "5                 NaN                 NaN            NaN  \n",
       "6                 NaN                 NaN            NaN  \n",
       "7                 NaN                 NaN            NaN  \n",
       "8                 NaN                 NaN            NaN  \n",
       "9                 NaN                 NaN            NaN  \n",
       "10                NaN                 NaN            NaN  \n",
       "11                NaN                 NaN            NaN  \n",
       "12       Not reported                 301            NaN  \n",
       "13                NaN                 NaN            NaN  \n",
       "14                NaN                 NaN            NaN  \n",
       "15       Not reported        Not reported            NaN  \n",
       "16              2,298                 552            NaN  \n",
       "17                  1                 225            NaN  \n",
       "18                NaN                 NaN            NaN  \n",
       "19       Not reported                 288                 \n",
       "20       Not reported                 481            NaN  \n",
       "21                NaN                 NaN            NaN  \n",
       "\n",
       "[21 rows x 261 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_URL_1 = \"https://www.collegedata.com/cs/data/college/college_pg0\"\n",
    "BASE_URL_2 = \"_tmpl.jhtml?schoolId=\"\n",
    "PAGE_IDS = np.arange(1, 7)\n",
    "SCHOOL_IDS = np.arange(1, 5000)\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "weird_soups = []\n",
    "errors = []\n",
    "def scrape_batch(batch_start):\n",
    "    batch = SCHOOL_IDS[batch_start : batch_start + BATCH_SIZE]\n",
    "    \n",
    "    urls = {school_id: \\\n",
    "            {page_id:BASE_URL_1 + str(page_id) + BASE_URL_2 + str(school_id) \\\n",
    "              for page_id in PAGE_IDS} \\\n",
    "               for school_id in batch}\n",
    "\n",
    "    session = FuturesSession()\n",
    "    reqs = {school_id: [session.get(url) for url in urls[school_id].values()] \\\n",
    "             for school_id in batch}\n",
    "\n",
    "    \n",
    "    scraped_batch = {}\n",
    "    for school_id in batch:\n",
    "        scraped_school = {}\n",
    "        name = None\n",
    "        for req in reqs[school_id]:\n",
    "            clear_output(wait = True)\n",
    "            result = req.result()\n",
    "            print(\"Scraping {}\".format(result.url))\n",
    "            print(\"Status Code: {}\".format(result.status_code))\n",
    "            \n",
    "            if result.status_code != 200:\n",
    "                error = \"Status Code {}\".format(result.status_code)\n",
    "                print(\"ERROR {} with {}\".format(error, result.url))\n",
    "                errors.append((result.url, result.status_code))\n",
    "                break\n",
    "            \n",
    "            soup = BeautifulSoup(result.text, \"lxml\")\n",
    "            \n",
    "            if not soup.h1:\n",
    "                error = \"No <h1> tag!\"\n",
    "                print(\"ERROR {} with {}\".format(error, result.url))\n",
    "                errors.append((result.url, error))\n",
    "                break\n",
    "            \n",
    "            if soup.h1.string == EMPTY_TITLE:\n",
    "                error = \"Empty page!\"\n",
    "                print(\"ERROR {} with {}\".format(error, result.url))\n",
    "                errors.append((result.url, error))\n",
    "                break\n",
    "                \n",
    "            preprocess_soup(soup)\n",
    "            scraped_page = scrape_page(soup)\n",
    "            \n",
    "            if len(scraped_page) == 1:\n",
    "                weird_soups.append(soup)\n",
    "            \n",
    "            \n",
    "            name = soup.h1.string\n",
    "            \n",
    "            add_dict(scraped_school, scraped_page)\n",
    "            \n",
    "        scraped_school['Name'] = name\n",
    "        scraped_batch[school_id] = scraped_school\n",
    "    \n",
    "    return scraped_batch\n",
    "\n",
    "\n",
    "\n",
    "SCHOOL_ID_END = 20\n",
    "scraped = {}\n",
    "for batch_start in range(0, SCHOOL_ID_END + 1, BATCH_SIZE):\n",
    "    scraped_batch = scrape_batch(batch_start)\n",
    "    scraped.update(scraped_batch)\n",
    "\n",
    "df = pd.DataFrame.from_dict(scraped, orient='index')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weird_soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bryn Athyn College'"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = weird_soups[0]\n",
    "\n",
    "#soup('h1')[0].parent.parent.next_sibling.next_sibling.next_sibling.next_sibling\n",
    "\n",
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "5         NaN\n",
       "6     Private\n",
       "7     Private\n",
       "8     Private\n",
       "9     Private\n",
       "10    Private\n",
       "11    Private\n",
       "12    Private\n",
       "13    Private\n",
       "14    Private\n",
       "15    Private\n",
       "16        NaN\n",
       "17    Private\n",
       "18    Private\n",
       "19    Private\n",
       "20    Private\n",
       "21    Private\n",
       "Name: Institution Type, dtype: object"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Institution Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get('http://www.vertuli.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
